{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the last assignment. It is different from the previous ones. \n",
    "\n",
    "#### This is optional, you should submit it only if you need more points for the better grade. <br> You can get 5 points completing this assignment. It has no automated grading system, so please upload your work to your github repository and send us (deeplearninginsciences@gmail.com) an email with it's link! \n",
    "\n",
    "#### This notebook is just a frame of your work, we have no pre-defined functions now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous assignment we built a model that can embed words to a vector space. It takes a while to train such a model, so in this assignment you will use a pre-trained model.\n",
    "\n",
    "I suggest using the **gensim** library, as we already have an  [example notebook](https://github.com/qati/DeepLearningCourse/blob/master/demo_notebooks/lecture_08/word2vec_application.ipynb) for it. \n",
    "\n",
    "You can download pre-trained weights from here: http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy dataset\n",
    "\n",
    "99 train (train_emoji.txt) and 46 test (test_emoji.txt) sentences are provided with corresponding emojis. They were downloaded as quotes with the corresponding tags (love, travel, etc..). But it's also possible to download real-time tweets.\n",
    "\n",
    "The toy dataset has 4 emojis, bee below (some browser may not display them correctly). In the dataset each line starts with a number, that is the coding for the emoji. Feel free to use it, or you can use other dataset too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is number 0: ‚ô•\n",
      "This is number 1: üòû\n",
      "This is number 2: üõ´\n",
      "This is number 3: üç¥\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.emojize('This is number 0: :heart_suit:'))\n",
    "print(emoji.emojize('This is number 1: :disappointed_face:'))\n",
    "print(emoji.emojize('This is number 2: :airplane_departure:'))\n",
    "print(emoji.emojize('This is number 3: :fork_and_knife:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your work:\n",
    "1. Convert each example to a vector. Simply convert all of it's words to vector and average them to get the vector for the sentence.\n",
    "2. Try different learning algorithms (tree based, fully connected neural networks or you may try LSTM) to train the emoji predictor. <br> Reaching ~70% accuracy on the validation set is fairly easy with neural networks\n",
    "3. Using the test examples validate your predictor's performance!\n",
    "4. Send us the link to your notebook which contains explanatory comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
