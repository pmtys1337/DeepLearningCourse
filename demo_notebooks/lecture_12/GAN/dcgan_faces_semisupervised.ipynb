{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Dense, Dropout, Reshape, Input,Flatten,BatchNormalization\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os,sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    faces = os.listdir(data_dir)\n",
    "    X = np.zeros((len(faces), 48,48))\n",
    "    Y = np.zeros((len(faces), 1))\n",
    "    for face in faces:\n",
    "        fid = int(face.replace(\".png\",\"\"))\n",
    "        X[fid-1,:,:] = np.array(imageio.imread(data_dir+face))[:,:,0]/255.\n",
    "        Y[fid-1, 0]  = int(df.loc[df[\"ID\"]==int(fid)][\"isHappy\"].values)\n",
    "    X  = X.reshape((-1,48,48,1))\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data(\"./faces/trainData/\", \"./faces/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = 2.*x_train-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train), np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "width      = x_train.shape[1]\n",
    "height     = x_train.shape[2]\n",
    "channels   = x_train.shape[3]\n",
    "latent_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(channels, f, strides=1, bn_mom=0.5, padding='same', lr=0.2):\n",
    "    def layer(x):\n",
    "        x = Conv2D(channels, f, strides=strides, padding = padding)(x)\n",
    "        if bn_mom:\n",
    "            x = BatchNormalization(momentum=bn_mom)(x)\n",
    "        x = LeakyReLU(lr)(x)\n",
    "        return x\n",
    "    return layer\n",
    "\n",
    "def deconv(channels, f, strides=2, bn_mom=0.5, padding='same', lr=0.01):\n",
    "    def layer(x):\n",
    "        x = Conv2DTranspose(channels, f, strides=strides, padding = padding)(x)\n",
    "        if bn_mom:\n",
    "            x = BatchNormalization(momentum=bn_mom)(x)\n",
    "        x = LeakyReLU(lr)(x)\n",
    "        return x\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4608)              299520    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 12, 12, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 24, 24, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 48, 48, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 1)         1601      \n",
      "=================================================================\n",
      "Total params: 4,215,553\n",
      "Trainable params: 4,212,609\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input = Input(shape=(latent_dim,))\n",
    "\n",
    "x = Dense(512*3*3)(generator_input)\n",
    "x = Reshape((3,3,512))(x)\n",
    "x = BatchNormalization(momentum=0.5)(x)\n",
    "x = LeakyReLU(0.01)(x)\n",
    "\n",
    "x = deconv(512, 3, 2)(x)\n",
    "x = deconv(256, 3, 2)(x)\n",
    "x = deconv(128, 3, 2)(x)\n",
    "x = deconv(64, 3, 2)(x)\n",
    "x = Conv2D(channels, 5, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = Model(generator_input, x)\n",
    "generator.summary()\n",
    "\n",
    "g_optimizer = Adam(lr=0.0001,beta_1=0.5, clipvalue=1.0, decay=1e-8)\n",
    "generator.compile(optimizer=g_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 48, 48, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 128)       1280      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 27651     \n",
      "=================================================================\n",
      "Total params: 6,231,043\n",
      "Trainable params: 6,227,459\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = Input(shape=(height, width, channels))\n",
    "\n",
    "x = conv(128, 3, strides=2, bn_mom=None)(discriminator_input)\n",
    "x = conv(256, 3, strides=2, bn_mom=0.5)(x)\n",
    "x = conv(512, 3, strides=2, bn_mom=0.5)(x)\n",
    "x = conv(1024, 3, strides=2, bn_mom=0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = Adam(lr=0.0001, beta_1=0.5, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 48, 48, 1)         4215553   \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 3)                 6231043   \n",
      "=================================================================\n",
      "Total params: 10,446,596\n",
      "Trainable params: 4,212,609\n",
      "Non-trainable params: 6,233,987\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = Adam(lr=0.00005, beta_1=0.5, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_optimizer = Adam(lr=0.0008, beta_1=0.5, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qati/.anaconda3/lib/python3.5/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch: 0\n",
      " step 90; discriminator_loss: 0.4116, adversarial_loss: 0.7058\n",
      " Epoch: 1\n",
      " step 190; discriminator_loss: 0.4423, adversarial_loss: 0.7643\n",
      " Epoch: 2\n",
      " step 290; discriminator_loss: 0.4056, adversarial_loss: 0.7157\n",
      " Epoch: 3\n",
      " step 390; discriminator_loss: 0.4354, adversarial_loss: 0.7178\n",
      " Epoch: 4\n",
      " step 490; discriminator_loss: 0.3749, adversarial_loss: 0.6949\n",
      " Epoch: 5\n",
      " step 590; discriminator_loss: 0.4952, adversarial_loss: 0.7228\n",
      " Epoch: 6\n",
      " step 690; discriminator_loss: 0.4002, adversarial_loss: 0.7029\n",
      " Epoch: 7\n",
      " step 790; discriminator_loss: 0.3948, adversarial_loss: 0.7052\n",
      " Epoch: 8\n",
      " step 890; discriminator_loss: 1.5848, adversarial_loss: 0.7437"
     ]
    }
   ],
   "source": [
    "iterations = 20000\n",
    "batch_size = 100\n",
    "save_dir = 'dcgan_images1_2'\n",
    "\n",
    "a_losses = []\n",
    "d_losses = []\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    \n",
    "    #-------------------------#\n",
    "    #   TRAIN DISCRIMINATOR   #\n",
    "    #-------------------------#\n",
    "\n",
    "    stop         = start+batch_size\n",
    "    real_images  = x_train[start:stop]\n",
    "    real_labels  = y_train[start:stop]\n",
    "\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    real_targets = to_categorical(np.ones((batch_size,1))+real_labels, num_classes=3)\n",
    "    real_targets += np.multiply(real_targets,0.4*np.random.randn(batch_size,3)-0.2)\n",
    "    \n",
    "    fake_targets = to_categorical(np.zeros((batch_size,1)), num_classes=3)\n",
    "    fake_targets[:,0] += 0.4*np.random.random((batch_size,))-0.2\n",
    "    \n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    if np.random.rand()<0.08:\n",
    "        real_loss = discriminator.train_on_batch(real_images, fake_targets)\n",
    "        fake_loss = discriminator.train_on_batch(generated_images, real_targets)\n",
    "    else:\n",
    "        real_loss = discriminator.train_on_batch(real_images, real_targets)\n",
    "        fake_loss = discriminator.train_on_batch(generated_images, fake_targets)    \n",
    "        \n",
    "    d_loss = 0.5*(real_loss+fake_loss)\n",
    "\n",
    "    d_losses.append(d_loss)\n",
    "    \n",
    "    #---------------------#\n",
    "    #   TRAIN GENERATOR   #\n",
    "    #---------------------#\n",
    "    for i in range(np.random.randint(1,4)):\n",
    "        random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "        misleading_targets    = to_categorical(2*np.ones((batch_size,1)))\n",
    "        a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "        \n",
    "    a_losses.append(a_loss)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start>(len(x_train)-batch_size):\n",
    "        start = 0\n",
    "    \n",
    "    if step % 10 ==0:\n",
    "        if not (step*batch_size)%len(x_train):\n",
    "            print(\"\\n Epoch: %d\"%(step*batch_size/float(len(x_train))))\n",
    "        sys.stdout.write('\\r step %d; discriminator_loss: %.4f, adversarial_loss: %.4f'%(step, d_loss,a_loss))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    if not (step*batch_size)%(2*len(x_train)):\n",
    "        epoch = step*batch_size/float(len(x_train))\n",
    "        gan.save_weights(\"gan_faces.h5\")\n",
    "        img = image.array_to_img((generated_images[0]+1.)*127.5, scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_face'+str(step)+'.png'))\n",
    "        \n",
    "        #img = image.array_to_img((real_images[0]+1.)*127.5, scale=False)\n",
    "        #img.save(os.path.join(save_dir, 'real_face'+str(step)+'.png'))\n",
    "        \n",
    "        with open(\"gan_loss_faces.csv\",\"w\") as f:\n",
    "            w = csv.writer(f, delimiter=',')\n",
    "            w.writerow([\"d_loss\", \"a_loss\"])\n",
    "            for i in range(len(d_losses)):\n",
    "                w.writerow([d_losses[i],a_losses[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
